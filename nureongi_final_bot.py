import asyncio
from telegram import Bot
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import pytz
import json
import os

BOT_TOKEN = "8591331989:AAEO0MuLnyFypcslPHMo8mWjW3LNy9BwejM"
CHAT_ID = "@gazzzza2025"

# ì¤‘ë³µ ë°©ì§€ìš© íŒŒì¼ ì €ì¥
SENT_NEWS_FILE = "sent_news.json"

KST = pytz.timezone('Asia/Seoul')

# ì „ì†¡í•œ ë‰´ìŠ¤ ì˜êµ¬ ì €ì¥
def load_sent_news():
    if os.path.exists(SENT_NEWS_FILE):
        with open(SENT_NEWS_FILE, 'r') as f:
            return set(json.load(f))
    return set()

def save_sent_news(sent_news):
    with open(SENT_NEWS_FILE, 'w') as f:
        json.dump(list(sent_news), f)

sent_news = load_sent_news()

async def send_news(bot, news_type, title, link, source=""):
    try:
        emoji_map = {
            "ì†ë³´": "ğŸ””",
            "ë‹¨ë…": "ğŸ¯",
            "ê¸°íš": "ğŸ“‹",
            "ì—¬ë¡ ì¡°ì‚¬": "ğŸ“Š"
        }
        emoji = emoji_map.get(news_type, "ğŸ“°")
        
        source_text = f"ğŸ“° {source}\n" if source else ""
        message = f"{emoji} <b>{news_type}</b>\n\n{title}\n\n{source_text}ğŸ”— {link}"
        await bot.send_message(CHAT_ID, message, parse_mode="HTML")
        print(f"âœ… [{news_type}] {title[:40]}... ({source})")
        return True
    except Exception as e:
        print(f"âŒ {e}")
        return False

async def fetch_naver_sections(bot):
    """ë„¤ì´ë²„ ì„¹ì…˜ë³„ - ì†ë³´/ë‹¨ë…/ê¸°íš/ì—¬ë¡ ì¡°ì‚¬ë§Œ"""
    sections = [
        ("100", "ì •ì¹˜"),
        ("101", "ê²½ì œ"),
        ("102", "ì‚¬íšŒ"),
        ("104", "êµ­ì œ"),
        ("105", "ITê³¼í•™"),
    ]
    
    for sid, name in sections:
        try:
            url = f"https://news.naver.com/section/{sid}"
            r = requests.get(url, headers={"User-Agent":"Mozilla/5.0"}, timeout=10)
            soup = BeautifulSoup(r.text, "html.parser")
            
            articles = soup.select("div.sa_text a.sa_text_title")[:10]
            
            for article in articles:
                title = article.get_text(strip=True)
                link = article.get("href", "")
                
                if not link or link in sent_news:
                    continue
                
                # [ì†ë³´] ìš°ì„ 
                if "[ì†ë³´]" in title:
                    await send_news(bot, "ì†ë³´", title, link, f"ë„¤ì´ë²„{name}")
                    sent_news.add(link)
                    save_sent_news(sent_news)
                    await asyncio.sleep(1)
                
                # [ë‹¨ë…] / (ë‹¨ë…)
                elif "[ë‹¨ë…]" in title or "(ë‹¨ë…)" in title:
                    await send_news(bot, "ë‹¨ë…", title, link, f"ë„¤ì´ë²„{name}")
                    sent_news.add(link)
                    save_sent_news(sent_news)
                    await asyncio.sleep(1)
                
                # [ê¸°íš] / (ê¸°íš)
                elif "[ê¸°íš]" in title or "(ê¸°íš)" in title:
                    await send_news(bot, "ê¸°íš", title, link, f"ë„¤ì´ë²„{name}")
                    sent_news.add(link)
                    save_sent_news(sent_news)
                    await asyncio.sleep(1)
                
                # ì—¬ë¡ ì¡°ì‚¬
                elif "ì—¬ë¡ ì¡°ì‚¬" in title:
                    await send_news(bot, "ì—¬ë¡ ì¡°ì‚¬", title, link, f"ë„¤ì´ë²„{name}")
                    sent_news.add(link)
                    save_sent_news(sent_news)
                    await asyncio.sleep(1)
                    
        except Exception as e:
            print(f"âŒ {name}: {e}")

async def fetch_naver_main(bot):
    """ë„¤ì´ë²„ ë©”ì¸ í—¤ë“œë¼ì¸ - ì†ë³´ë§Œ"""
    try:
        url = "https://news.naver.com/"
        r = requests.get(url, headers={"User-Agent":"Mozilla/5.0"}, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
        
        headlines = soup.select("a.cjs_news_tw, a.cjs_t")[:20]
        
        for headline in headlines:
            title = headline.get_text(strip=True)
            link = headline.get("href", "")
            
            if not link or link in sent_news:
                continue
            
            if not link.startswith("http"):
                link = "https://news.naver.com" + link
            
            # [ì†ë³´]ë§Œ
            if "[ì†ë³´]" in title:
                await send_news(bot, "ì†ë³´", title, link, "ë„¤ì´ë²„ë©”ì¸")
                sent_news.add(link)
                save_sent_news(sent_news)
                await asyncio.sleep(1)
                
    except Exception as e:
        print(f"âŒ ë„¤ì´ë²„ë©”ì¸: {e}")

async def main():
    print("ğŸ¤– ëˆ„ë ë´‡ ìµœì¢…íŒ!")
    print("ğŸ“° ë„¤ì´ë²„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
    print("ğŸ”” [ì†ë³´] + ğŸ¯ [ë‹¨ë…] + ğŸ“‹ [ê¸°íš] + ğŸ“Š ì—¬ë¡ ì¡°ì‚¬")
    print("ğŸ“¢ ì±„ë„: @gazzzza2025")
    print("â° 1ë¶„ë§ˆë‹¤ í™•ì¸\n")
    print(f"ğŸ“ ì €ì¥ëœ ë‰´ìŠ¤: {len(sent_news)}ê°œ\n")
    
    bot = Bot(BOT_TOKEN)
    
    try:
        now = datetime.now(KST).strftime('%Y-%m-%d %H:%M:%S')
        await bot.send_message(
            CHAT_ID, 
            f"ğŸ¤– <b>ëˆ„ë ë´‡ ìµœì¢…íŒ</b>\n\n"
            f"â° {now}\n"
            f"ğŸ“° ë„¤ì´ë²„ ì‹¤ì‹œê°„ [ì†ë³´] [ë‹¨ë…] [ê¸°íš] ì—¬ë¡ ì¡°ì‚¬\n"
            f"âœ… ì¤‘ë³µ ë°©ì§€ ì‹œìŠ¤í…œ í™œì„±í™”",
            parse_mode="HTML"
        )
    except:
        pass
    
    while True:
        print(f"â° {datetime.now(KST).strftime('%H:%M:%S')} - ë‰´ìŠ¤ í™•ì¸ ì¤‘...")
        
        # ë„¤ì´ë²„ ë©”ì¸ (ì†ë³´ë§Œ)
        await fetch_naver_main(bot)
        
        # ë„¤ì´ë²„ ì„¹ì…˜ë³„ (ì†ë³´/ë‹¨ë…/ê¸°íš/ì—¬ë¡ ì¡°ì‚¬)
        await fetch_naver_sections(bot)
        
        print("â³ 1ë¶„ ëŒ€ê¸°...\n")
        await asyncio.sleep(60)

asyncio.run(main())
