import requests
from bs4 import BeautifulSoup

sites = {
    "Ground News": "https://ground.news/",
    "AI Times": "https://www.aitimes.com/",
    "Coinness": "https://coinness.com/news"
}

for name, url in sites.items():
    print(f"\n{'='*60}")
    print(f"ğŸ“° {name}: {url}")
    print('='*60)
    
    try:
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        soup = BeautifulSoup(r.text, "html.parser")
        
        # ì œëª© ë§í¬ ì°¾ê¸° (ì¼ë°˜ì ì¸ ì…€ë ‰í„°ë“¤)
        selectors = [
            "article a",
            "div.news a",
            "div.article a", 
            "h2 a",
            "h3 a",
            "a.title",
            "a.headline"
        ]
        
        found = False
        for selector in selectors:
            articles = soup.select(selector)[:3]
            if articles:
                print(f"\nâœ… ì…€ë ‰í„°: {selector}")
                for i, a in enumerate(articles, 1):
                    title = a.get_text(strip=True)
                    link = a.get("href", "")
                    if title and len(title) > 10:
                        print(f"  {i}. {title[:60]}...")
                        print(f"     ë§í¬: {link[:80]}...")
                        found = True
                if found:
                    break
        
        if not found:
            print("âŒ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")

print("\n" + "="*60)
