"""ëˆ„ë ì´ ì‚¬ì„¤ë´‡ - ë§¤ì¼ ì•„ì¹¨ 15ê°œ ì‹ ë¬¸ ì‚¬ì„¤ (Google News RSS)"""
import os
import requests
import logging
from bs4 import BeautifulSoup
from datetime import datetime

logger = logging.getLogger(__name__)

BOT_TOKEN = os.environ.get('SCHEDULE_BOT_TOKEN', '8734510853:AAHsqC3fQfC0K02-xrWEZgnh9ZDGUIi2P44')
CHAT_ID = '5132309076'
HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)'}

PAPERS = {
    'ì¢…í•©ì§€': ['ê²½í–¥ì‹ ë¬¸', 'êµ­ë¯¼ì¼ë³´', 'ë™ì•„ì¼ë³´', 'ì„œìš¸ì‹ ë¬¸', 'ì„¸ê³„ì¼ë³´', 'ì¡°ì„ ì¼ë³´', 'ì¤‘ì•™ì¼ë³´', 'í•œê²¨ë ˆ', 'í•œêµ­ì¼ë³´'],
    'ê²½ì œì§€': ['ë””ì§€í„¸íƒ€ì„ìŠ¤', 'ë§¤ì¼ê²½ì œ', 'ì„œìš¸ê²½ì œ', 'ì´ë°ì¼ë¦¬', 'íŒŒì´ë‚¸ì…œë‰´ìŠ¤', 'í•œêµ­ê²½ì œ'],
}


def get_editorials_google(paper_name, limit=3):
    """Google News RSSë¡œ ì‚¬ì„¤ ê²€ìƒ‰"""
    try:
        query = f'{paper_name} ì‚¬ì„¤'
        url = f'https://news.google.com/rss/search?q={requests.utils.quote(query)}&hl=ko&gl=KR&ceid=KR:ko'
        r = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(r.text, 'xml')

        today = datetime.now().strftime('%Y')
        titles = []
        for item in soup.select('item')[:10]:
            title = item.select_one('title').text.strip()
            # [ì‚¬ì„¤] íƒœê·¸ ìˆëŠ” ê²ƒë§Œ + ì–¸ë¡ ì‚¬ëª… ì œê±°
            if True:  # ëª¨ë“  ê²°ê³¼ ìˆ˜ì§‘ (Google ê²€ìƒ‰ì´ ì´ë¯¸ í•„í„°ë§)
                clean = title.split(' - ')[0].strip()
                clean = clean.replace('[ì‚¬ì„¤]', '').replace('[ì‚¬ì„¤] ', '').strip()
                if clean and len(clean) > 5:
                    titles.append(clean)
        return titles[:limit]
    except Exception as e:
        logger.error(f"{paper_name} ì‚¬ì„¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


def format_message(editorials):
    """í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í¬ë§·"""
    lines = ['ğŸ—ï¸ <b>ì£¼ìš” ì‹ ë¬¸ ì‚¬ì„¤</b> ğŸ—ï¸\n']

    for category, papers in editorials.items():
        lines.append(f'\n<b>*{category}*</b>')
        for name, titles in papers.items():
            lines.append(f'â—‡{name}')
            if titles:
                for t in titles:
                    lines.append(f'-{t}')
            else:
                lines.append('-ì‚¬ì„¤ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤')

    lines.append(f'\nì¶œì²˜: https://t.me/gazzzza2025')
    lines.append('(ì‹¤ì‹œê°„ í…”ë ˆê·¸ë¨ ì •ë³´ë°©)')
    return '\n'.join(lines)


def send_editorial():
    """ì‚¬ì„¤ ìˆ˜ì§‘ í›„ í…”ë ˆê·¸ë¨ ì „ì†¡"""
    logger.info("=== ì‚¬ì„¤ë´‡ ì‹œì‘ ===")
    print("ì‚¬ì„¤ë´‡ ì‹œì‘...")

    editorials = {}
    for category, papers in PAPERS.items():
        editorials[category] = {}
        for name in papers:
            titles = get_editorials_google(name)
            editorials[category][name] = titles
            print(f"  {name}: {len(titles)}ê°œ")

    message = format_message(editorials)

    # 4096ì ë¶„í• 
    if len(message) > 4000:
        parts = []
        current = ""
        for line in message.split('\n'):
            if len(current) + len(line) + 1 > 4000:
                parts.append(current)
                current = line
            else:
                current += '\n' + line if current else line
        if current:
            parts.append(current)
    else:
        parts = [message]

    try:
        url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
        for part in parts:
            resp = requests.post(url, json={
                'chat_id': CHAT_ID,
                'text': part,
                'parse_mode': 'HTML',
                'disable_web_page_preview': True,
            }, timeout=10)
            if resp.status_code == 200:
                print(f"ì „ì†¡ ì™„ë£Œ ({len(part)}ì)")
            else:
                print(f"ì „ì†¡ ì‹¤íŒ¨: {resp.text}")

        logger.info("=== ì‚¬ì„¤ë´‡ ì™„ë£Œ ===")
        print("ì‚¬ì„¤ë´‡ ì™„ë£Œ âœ…")
    except Exception as e:
        logger.error(f"ì‚¬ì„¤ë´‡ ì˜¤ë¥˜: {e}")
        print(f"ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    send_editorial()
