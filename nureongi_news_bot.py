"""ëˆ„ë ì´ ë‰´ìŠ¤ë´‡ - í•œê¸€ ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§"""
import os
import asyncio
import requests
import json
from bs4 import BeautifulSoup
from telegram import Bot
from datetime import datetime, timezone, timedelta
import pytz

BOT_TOKEN = os.environ.get('NUREONGI_NEWS_BOT_TOKEN')
CHAT_ID = "@gazzzza2025"
KST = pytz.timezone('Asia/Seoul')

# ì¤‘ë³µ ë°©ì§€ - íŒŒì¼ë¡œ ì˜êµ¬ ì €ì¥
SENT_FILE = '/tmp/sent_news.json'

def load_sent_news():
    try:
        with open(SENT_FILE, 'r') as f:
            return set(json.load(f))
    except:
        return set()

def save_sent_news(sent):
    try:
        with open(SENT_FILE, 'w') as f:
            json.dump(list(sent), f)
    except:
        pass

KEYWORDS = [
    "ì‚¼ì„±", "SK", "LG", "í˜„ëŒ€", "AI", "ì±—GPT", "í…ŒìŠ¬ë¼", "ì—”ë¹„ë””ì•„",
    "í™˜ìœ¨", "ê¸ˆë¦¬", "HBM", "ë°˜ë„ì²´", "ë¨¸ìŠ¤í¬", "ì• í”Œ", "ì½”ìŠ¤í”¼",
    "íŒ”ë€í‹°ì–´", "ì•ˆë‘ë¦´", "UAM", "AAM", "ë“œë¡ ", "í´ë¡œë“œ", "ì  ìŠ¨í™©",
    "í”¼í„°í‹¸", "ì•„ëª¨ë°ì´",
    "ì´ì¬ëª…", "ì¥ë™í˜", "í•œë™í›ˆ", "ë¯¼ì£¼ë‹¹", "êµ­ë¯¼ì˜í˜",
    "ì •ì²­ë˜", "ì¡°êµ­", "ê¹€ì–´ì¤€", "ìœ¤ì„ì—´", "ê¹€ê±´í¬",
    "ì´ì¤€ì„", "ì„ ê±°", "ì§€ë°©ì„ ê±°",
    "íŠ¸ëŸ¼í”„", "í‘¸í‹´", "ì‹œì§„í•‘", "ë‹¤ì¹´ì´ì¹˜", "ë„¤íƒ€ëƒí›„", "ì—ë¥´ë„ì•ˆ",
]

SPECIAL_TAGS = ['[ë‹¨ë…]', '[ì†ë³´]', '[ì—¬ë¡ ì¡°ì‚¬]', '[ê¸°íš]', '[ì¸í„°ë·°]', '(ë‹¨ë…)']

SOURCES = [
    ("ê²½ì œ", "https://news.naver.com/section/101"),
    ("ì •ì¹˜", "https://news.naver.com/section/100"),
    ("IT/ê³¼í•™", "https://news.naver.com/section/105"),
    ("ì„¸ê³„", "https://news.naver.com/section/104"),
]

def get_article_time(link):
    """ê¸°ì‚¬ í˜ì´ì§€ì—ì„œ ì‘ì„± ì‹œê°„ ì¶”ì¶œ"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(link, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        # ë„¤ì´ë²„ ë‰´ìŠ¤ ë‚ ì§œ íƒœê·¸
        time_tag = soup.select_one('.media_end_head_info_datestamp_time, ._ARTICLE_DATE_TIME')
        if time_tag:
            dt_str = time_tag.get('data-date-time') or time_tag.get_text(strip=True)
            if dt_str:
                dt = datetime.fromisoformat(dt_str.replace('Z', '+00:00'))
                return dt
    except:
        pass
    return None

def get_news():
    """ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ - 1ì‹œê°„ ì´ë‚´ ê¸°ì‚¬ë§Œ"""
    articles = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    now = datetime.now(timezone.utc)
    one_hour_ago = now - timedelta(hours=1)

    for section_name, url in SOURCES:
        try:
            res = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')
            items = soup.select('a.sa_text_title')

            for item in items[:20]:
                title = item.get_text(strip=True)
                link = item.get('href', '')
                if not link.startswith('http'):
                    continue

                # í‚¤ì›Œë“œ ë˜ëŠ” íŠ¹ìˆ˜íƒœê·¸ í•„í„°
                matched = (
                    any(tag in title for tag in SPECIAL_TAGS) or
                    any(kw in title for kw in KEYWORDS)
                )
                if not matched:
                    continue

                # 1ì‹œê°„ ì´ë‚´ ê¸°ì‚¬ë§Œ
                article_time = get_article_time(link)
                if article_time and article_time < one_hour_ago:
                    continue

                articles.append((title, link, section_name))

        except Exception as e:
            print(f"í¬ë¡¤ë§ ì˜¤ë¥˜ [{section_name}]: {e}")

    return articles

async def send_news():
    """ìƒˆ ë‰´ìŠ¤ í…”ë ˆê·¸ë¨ ì „ì†¡"""
    if not BOT_TOKEN:
        print("NUREONGI_NEWS_BOT_TOKEN í™˜ê²½ë³€ìˆ˜ ì—†ìŒ")
        return

    sent_news = load_sent_news()
    bot = Bot(BOT_TOKEN)
    articles = get_news()
    new_count = 0

    for title, link, section in articles:
        if link in sent_news:
            continue

        sent_news.add(link)
        tags = [f"#{kw}" for kw in KEYWORDS if kw in title]
        tag_str = " ".join(tags[:3])

        section_emoji = {
            "ê²½ì œ": "ğŸ’°", "ì •ì¹˜": "ğŸ›ï¸", "IT/ê³¼í•™": "ğŸ’»", "ì„¸ê³„": "ğŸŒ"
        }.get(section, "ğŸ“°")

        message = (
            f"{section_emoji} <b>[{section}] ë‰´ìŠ¤ ì•Œë¦¼</b>\n\n"
            f"{title}\n\n"
            f"{tag_str}\n"
            f"ğŸ”— {link}"
        )

        try:
            await bot.send_message(
                CHAT_ID,
                message,
                parse_mode="HTML",
                disable_web_page_preview=True
            )
            print(f"âœ… [{section}] {title[:30]}")
            new_count += 1
            await asyncio.sleep(2)
        except Exception as e:
            print(f"âŒ ì „ì†¡ ì‹¤íŒ¨: {e}")

    save_sent_news(sent_news)
    print(f"[ë‰´ìŠ¤ë´‡] ì™„ë£Œ â€” {new_count}ê°œ ì „ì†¡")

def run_news_bot():
    asyncio.run(send_news())
